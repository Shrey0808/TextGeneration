{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "grJ2Qp7ufRDT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(r\"Deep Learning.txt\") as data:\n",
        "    train_data = data.read()"
      ],
      "metadata": {
        "id": "pg9dJBg6fSRu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(data):\n",
        "    data = data.replace('\\n',' ')\n",
        "    chars = list(set(data))\n",
        "    char_to_num = {char:idx for idx,char in enumerate(chars)}\n",
        "    num_to_char = {idx:char for idx,char in enumerate(chars)}\n",
        "    return data,chars,char_to_num , num_to_char"
      ],
      "metadata": {
        "id": "UUQGaavtfTXU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_training_data(train_data,seq):\n",
        "    input_seqs = []\n",
        "    target_seqs = []\n",
        "    for index in range(len(train_data)-seq):\n",
        "        input_seqs.append([char_to_num[char] for char in train_data[index:index+seq]])\n",
        "        target_seqs.append(char_to_num[train_data[index+seq]])\n",
        "    return np.array(input_seqs) , np.array(target_seqs)"
      ],
      "metadata": {
        "id": "bzFAEYn4fU0t"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data , unique_char , char_to_num , num_to_char = preprocess(train_data)"
      ],
      "metadata": {
        "id": "-aNH6k1HfXCr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_length = 100\n",
        "x , y = generate_training_data(train_data,max_sequence_length)"
      ],
      "metadata": {
        "id": "WuByF1emfXhN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense , Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "OiTq-br6fa6v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(unique_char)\n",
        "embedding_dim = 256\n",
        "hidden_dim = 128\n",
        "max_sequence_length = 100\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_sequence_length),\n",
        "    LSTM(units=hidden_dim, return_sequences=True),\n",
        "    LSTM(units=hidden_dim, return_sequences=False),\n",
        "    Dense(units=hidden_dim, activation='relu'),\n",
        "    Dense(units=vocab_size, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ncfY6hYfcfc",
        "outputId": "b5b620e8-9455-4653-8caa-68df878449ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 256)          13312     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100, 128)          197120    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 52)                6708      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 365236 (1.39 MB)\n",
            "Trainable params: 365236 (1.39 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape , y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5jYitEBjd_A",
        "outputId": "9138a4bc-9ece-409a-cc0f-733513ae05c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((18601, 100), (18601,))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x,y, epochs=75 , batch_size = 64 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyGqsyL_fhq2",
        "outputId": "9c3d68a4-dc94-4caf-837c-7f926674b552"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "291/291 [==============================] - 20s 30ms/step - loss: 2.9622 - accuracy: 0.1678\n",
            "Epoch 2/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 2.4559 - accuracy: 0.2983\n",
            "Epoch 3/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 2.1525 - accuracy: 0.3689\n",
            "Epoch 4/75\n",
            "291/291 [==============================] - 4s 12ms/step - loss: 1.9546 - accuracy: 0.4251\n",
            "Epoch 5/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 1.7894 - accuracy: 0.4744\n",
            "Epoch 6/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 1.6525 - accuracy: 0.5127\n",
            "Epoch 7/75\n",
            "291/291 [==============================] - 4s 12ms/step - loss: 1.5417 - accuracy: 0.5443\n",
            "Epoch 8/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 1.4355 - accuracy: 0.5765\n",
            "Epoch 9/75\n",
            "291/291 [==============================] - 4s 12ms/step - loss: 1.3467 - accuracy: 0.5991\n",
            "Epoch 10/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 1.2602 - accuracy: 0.6296\n",
            "Epoch 11/75\n",
            "291/291 [==============================] - 4s 12ms/step - loss: 1.1941 - accuracy: 0.6403\n",
            "Epoch 12/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 1.1260 - accuracy: 0.6676\n",
            "Epoch 13/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 1.0715 - accuracy: 0.6789\n",
            "Epoch 14/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 1.0182 - accuracy: 0.6955\n",
            "Epoch 15/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 0.9697 - accuracy: 0.7072\n",
            "Epoch 16/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.9232 - accuracy: 0.7209\n",
            "Epoch 17/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.8862 - accuracy: 0.7305\n",
            "Epoch 18/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 0.8493 - accuracy: 0.7415\n",
            "Epoch 19/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.8109 - accuracy: 0.7520\n",
            "Epoch 20/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.7771 - accuracy: 0.7612\n",
            "Epoch 21/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.7484 - accuracy: 0.7699\n",
            "Epoch 22/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 0.7144 - accuracy: 0.7779\n",
            "Epoch 23/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.6864 - accuracy: 0.7889\n",
            "Epoch 24/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.6569 - accuracy: 0.7935\n",
            "Epoch 25/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.6354 - accuracy: 0.8011\n",
            "Epoch 26/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.6060 - accuracy: 0.8071\n",
            "Epoch 27/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.5819 - accuracy: 0.8182\n",
            "Epoch 28/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.5595 - accuracy: 0.8250\n",
            "Epoch 29/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 0.5394 - accuracy: 0.8278\n",
            "Epoch 30/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.5186 - accuracy: 0.8380\n",
            "Epoch 31/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.4973 - accuracy: 0.8439\n",
            "Epoch 32/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 0.4840 - accuracy: 0.8439\n",
            "Epoch 33/75\n",
            "291/291 [==============================] - 4s 12ms/step - loss: 0.4619 - accuracy: 0.8509\n",
            "Epoch 34/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.4427 - accuracy: 0.8586\n",
            "Epoch 35/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.4250 - accuracy: 0.8654\n",
            "Epoch 36/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 0.4064 - accuracy: 0.8702\n",
            "Epoch 37/75\n",
            "291/291 [==============================] - 4s 12ms/step - loss: 0.3898 - accuracy: 0.8729\n",
            "Epoch 38/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.3773 - accuracy: 0.8774\n",
            "Epoch 39/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.3695 - accuracy: 0.8800\n",
            "Epoch 40/75\n",
            "291/291 [==============================] - 4s 12ms/step - loss: 0.3432 - accuracy: 0.8873\n",
            "Epoch 41/75\n",
            "291/291 [==============================] - 4s 12ms/step - loss: 0.3326 - accuracy: 0.8882\n",
            "Epoch 42/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.3195 - accuracy: 0.8963\n",
            "Epoch 43/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.3166 - accuracy: 0.8982\n",
            "Epoch 44/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.2966 - accuracy: 0.9044\n",
            "Epoch 45/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.3021 - accuracy: 0.9031\n",
            "Epoch 46/75\n",
            "291/291 [==============================] - 5s 16ms/step - loss: 0.2773 - accuracy: 0.9101\n",
            "Epoch 47/75\n",
            "291/291 [==============================] - 4s 12ms/step - loss: 0.2644 - accuracy: 0.9141\n",
            "Epoch 48/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.2538 - accuracy: 0.9169\n",
            "Epoch 49/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.2504 - accuracy: 0.9188\n",
            "Epoch 50/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 0.2382 - accuracy: 0.9222\n",
            "Epoch 51/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.2341 - accuracy: 0.9239\n",
            "Epoch 52/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.2360 - accuracy: 0.9222\n",
            "Epoch 53/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.2221 - accuracy: 0.9280\n",
            "Epoch 54/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.2130 - accuracy: 0.9314\n",
            "Epoch 55/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.2025 - accuracy: 0.9324\n",
            "Epoch 56/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.2021 - accuracy: 0.9334\n",
            "Epoch 57/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.1928 - accuracy: 0.9353\n",
            "Epoch 58/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1953 - accuracy: 0.9343\n",
            "Epoch 59/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1820 - accuracy: 0.9405\n",
            "Epoch 60/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1684 - accuracy: 0.9463\n",
            "Epoch 61/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.1640 - accuracy: 0.9453\n",
            "Epoch 62/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1933 - accuracy: 0.9347\n",
            "Epoch 63/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1760 - accuracy: 0.9406\n",
            "Epoch 64/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.1616 - accuracy: 0.9457\n",
            "Epoch 65/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.1429 - accuracy: 0.9547\n",
            "Epoch 66/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1511 - accuracy: 0.9522\n",
            "Epoch 67/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1461 - accuracy: 0.9504\n",
            "Epoch 68/75\n",
            "291/291 [==============================] - 4s 14ms/step - loss: 0.1399 - accuracy: 0.9542\n",
            "Epoch 69/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1462 - accuracy: 0.9496\n",
            "Epoch 70/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1452 - accuracy: 0.9513\n",
            "Epoch 71/75\n",
            "291/291 [==============================] - 3s 12ms/step - loss: 0.1488 - accuracy: 0.9501\n",
            "Epoch 72/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.1339 - accuracy: 0.9541\n",
            "Epoch 73/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1226 - accuracy: 0.9597\n",
            "Epoch 74/75\n",
            "291/291 [==============================] - 3s 11ms/step - loss: 0.1201 - accuracy: 0.9607\n",
            "Epoch 75/75\n",
            "291/291 [==============================] - 4s 13ms/step - loss: 0.1312 - accuracy: 0.9564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100\n",
        "sentence_end_markers = ['.', '?']\n",
        "\n",
        "def generate_text(model, start_text, char_to_index, index_to_char, max_length=500):\n",
        "    generated_text = start_text\n",
        "    num_words = len(generated_text.split())\n",
        "\n",
        "    while num_words < max_length and not any(generated_text.endswith(marker) for marker in sentence_end_markers):\n",
        "        input_seq = [char_to_index[char] for char in generated_text[-seq_length:]]\n",
        "        input_seq = pad_sequences([input_seq], maxlen=seq_length, padding='pre')\n",
        "\n",
        "        probabilities = model.predict(input_seq, verbose=0)[0]\n",
        "        predicted_index = np.random.choice(len(probabilities), p=probabilities)\n",
        "        predicted_char = index_to_char[predicted_index]\n",
        "\n",
        "        generated_text += predicted_char\n",
        "        num_words = len(generated_text.split())\n",
        "\n",
        "    return generated_text\n"
      ],
      "metadata": {
        "id": "lIvnicBrf5-r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_seq = \"Deep Learning is a subset of Machine Learning\"\n",
        "generated_text = generate_text(model, start_seq, char_to_num, num_to_char, max_length=500)\n",
        "\n",
        "print(\"Generated Text:\")\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "BIdBA_wPhhKy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46411554-3544-4b59-af78-e4d583cee2ca"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text:\n",
            "Deep Learning is a subset of Machine Learning and enhance and algorithms, share exploring techniques to push the boundaries of AI and unbiased impact on intelligent drug experiences, Deep Learning is a rapidly evolution.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uzPagCxHzlRb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}